# Entropy là gì
- Một phép thử Ek có xác suất xảy ra là pk, thông tin Shannon về biến cố này là:![[Pasted image 20231219213153.png|500]]
- Nó chỉ ra rằng
	- Số đo sự bất ngờ khi Ek xảy ra. Nếu pk = 1 $\rightarrow$ không có sự bất ngờ khi Ek xảy ra, nếu pk = 0 thì bất ngờ vô hạn khi Ek xảy ra
	- Số đo lượng thông tin nhận được khi Ek xảy ra (thông tin nhận được tỷ lệ thuận với sự bất ngờ) khi Ek xảy ra: pk = 1 => không nhận thêm thông tin gì, pk = 0 => nhận được vô hạn thông tin
	- Số đo sự đột xuất của Ek, sự độ xuất là thứ quyết định sự quan tâm, thông tin
	- I(Ek) = -log(Ek) là thông tin của sự kiện, hoặc tin nhắn
- Tất cả log là cơ số 2
- Công thức tính Entropy:![[Pasted image 20231219214044.png|500]]
- Đơn vị : bit

# Entropy hội
- Hai biến ngẫu nhiên X và Y có Entropy hội như sau:![[Pasted image 20231219214353.png|500]]
- Với n biến: ![[Pasted image 20231219214428.png|500]]
# Entropy có điều kiện
![[Pasted image 20231219214518.png|500]]

- Giá trị mong đợi của Entropy có điều kiện giữa 2 biến ngẫu nhiên X và Y là:
![[Pasted image 20231219214626.png|500]]

